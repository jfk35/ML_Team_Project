1+2
pkgs <- c('tidyverse', 'knitr', 'flexdashboard', 'nycflights13', 'ggmap')
install.packages(pkgs)
B = [1,0,0;0,1,0;0,0,1]
print(inv(B))
B = matrix(c(1,0,0
0,1,0
0,0,1), nrow=3, byrow=TRUE)
B = matrix(c(1,0,0,
0,1,0,
0,0,1), nrow=3, byrow=TRUE)
B = matrix(c(1,0,0,
0,1,0,
0,0,1), nrow=3, byrow=TRUE)
print(inv(B))
print(solve(B))
B = matrix(c(1,0,0,
0,1,0,
1,0,1), nrow=3, byrow=TRUE)
print(solve(B))
B = matrix(c(-1,1,0,
-1,0,1,
2,1,0), nrow=3, byrow=TRUE)
print(solve(B))
b = vector(c(1,1,4))
print(solve(B)*b)
b = c(1,1,4)
print(solve(B)*b)
print(solve(B).*b)
print(solve(B)%*%b)
for i=1:4:
print(i)
print(c[1])
c = c(1,-1,0,0,1,0,0)
print(c[1])
print(c[1] - cb%*%solve(B)%*%A[:1])
print(c[1] - cb%*%solve(B)%*%A[:,1])
print(c[1] - cb%*%solve(B)%*%A[,1])
c = c(1,-1,0,0,1,0,0)
cb = c(-1,0,0)
print(c[1])
print(c[1] - cb%*%solve(B)%*%A[,1])
A = matrix(c(1,-1,1,-1,1,0,0,
1,-1,0,0,0,1,0,
-2,2,1,-1,0,0,1), nrow = 3, byrow=TRUE)
B = matrix(c(-1,1,0,
-1,0,1,
2,1,0), nrow=3, byrow=TRUE)
b = c(1,1,4)
c = c(1,-1,0,0,1,0,0)
cb = c(-1,0,0)
print(c[1])
print(c[1] - cb%*%solve(B)%*%A[,1])
print(c[2] - cb%*%solve(B)%*%A[,2])
print(c[3] - cb%*%solve(B)%*%A[,3])
print(c[4] - cb%*%solve(B)%*%A[,4])
print(c[5] - cb%*%solve(B)%*%A[,5])
print(c[6] - cb%*%solve(B)%*%A[,6])
print(c[7] - cb%*%solve(B)%*%A[,7])
print(cb %*% solve(B))
c = c(0,0,-1,1,0,0,0)
cb = c(-1,0,0)
print(c[1])
print(c[1] - cb%*%solve(B)%*%A[,1])
print(c[2] - cb%*%solve(B)%*%A[,2])
print(c[3] - cb%*%solve(B)%*%A[,3])
print(c[4] - cb%*%solve(B)%*%A[,4])
print(c[5] - cb%*%solve(B)%*%A[,5])
print(c[1] - cb%*%solve(B)%*%A[,1])
print(c[1] - cb%*%solve(B)%*%A[,1])
A = matrix(c(1,-1,1,-1,1,0,0,
1,-1,0,0,0,1,0,
-2,2,1,-1,0,0,1), nrow = 3, byrow=TRUE)
B = matrix(c(-1,1,0,
-1,0,1,
2,1,0), nrow=3, byrow=TRUE)
b = c(1,1,4)
c = c(1,-1,0,0,1,0,0)
cb = c(-1,0,0)
print(c[1])
print(c[1] - cb%*%solve(B)%*%A[,1])
print(c[2] - cb%*%solve(B)%*%A[,2])
library(pracma)
xvals <- seq(-1, 1, by = 0.02)
Approx <- vector(length = length(xvals))
Func <- vector(length = length(xvals))
Error <- vector(length = length(xvals))
#Obtain the taylor expansion coefficients near 0
coefs <- taylor(exp, 0, n=4)
for (i in 1:101){
x <- xvals[i]
approx <- coefs[0] + coefs[1] * x + coefs[2] * x^2 + coefs[3] *x^3 + coefs[4] *x^4
func <- exp(x)
error <- func - approx
Approx[i] <- approx
Func[i] <- func
Error[i] <- error
}
plotData <- data.frame(X = xvals, fx = Func, approx = Approx, error = Error )
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = approx) + geom_line() + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
library(tidyverse)
library(ggplot2)
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = approx) + geom_line() + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
#Obtain the taylor expansion coefficients near 0
coefs <- taylor(exp, 0, n=4)
for (i in 1:101){
x <- xvals[i]
approx <- coefs[0] + coefs[1] * x + coefs[2] * x^2 + coefs[3] *x^3 + coefs[4] *x^4
func <- exp(x)
error <- func - approx
Approx[i] <- approx
Func[i] <- func
Error[i] <- error
}
print(coefs[0])
print(coefs[1])
for (i in 1:101){
x <- xvals[i]
approx <- coefs[1] + coefs[2] * x + coefs[3] * x^2 + coefs[4] *x^3 + coefs[5] *x^4
func <- exp(x)
error <- func - approx
Approx[i] <- approx
Func[i] <- func
Error[i] <- error
}
plotData <- data.frame(X = xvals, fx = Func, approx = Approx, error = Error )
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = approx) + geom_line() + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = error) + geom_line() + xlab('X') + ylab('Error') + ggtitle('Error in Taylor Expansion of e^x')
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = approx) + geom_line() +  geom_line() + aes(x = X, y = fx) + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = approx) + geom_line() + ggplot()+ geom_line() + aes(x = X, y = fx) + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
#Plot approximate error
p <- ggplot() + geom_line(data = plotData, aes(x = X, y = approx), color = "black") + geom_line(data = plotData, aes(x = X, y = fx), color = "red")  + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
print(p)
library(pracma)
library(ggplot2)
library(tidyverse)
xvals <- seq(-1, 1, by = 0.02)
Approx <- vector(length = length(xvals))
Func <- vector(length = length(xvals))
Error <- vector(length = length(xvals))
for (i in 1:101){
x <- xvals[i]
approx <- 1.000090015652939 + 0.997308719094761 * x + 0.4988353081494804 * x^2 + 0.17734594582439273 *x^3 + 0.044155311012809464 *x^4
func <- exp(x)
error <- func - approx
Approx[i] <- approx
Func[i] <- func
Error[i] <- error
}
plotData <- data.frame(X = xvals, fx = Func, approx = Approx, error = Error )
#Plot approximate error
p <- ggplot() + geom_line(data = plotData, aes(x = X, y = approx), color = "black") + geom_line(data = plotData, aes(x = X, y = fx), color = "red")  + xlab('X') + ylab('Approximation') + ggtitle('Polynomial Approximation of e^x near 0')
print(p)
#Plot approximate error
p <- ggplot() + geom_line(data = plotData, aes(x = X, y = fx), color = "red")  + xlab('X') + ylab('Approximation') + geom_line(data = plotData, aes(x = X, y = approx), color = "black")  + ggtitle('Polynomial Approximation of e^x near 0')
print(p)
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = error) + geom_line() + xlab('X') + ylab('Error') + ggtitle('Error in Polynomial Approximation')
#Obtain the taylor expansion coefficients near 0
coefs <- taylor(exp, 0, n=4)
print(coefs[i])
for (i in 1:5){
print(coefs[i])
}
for (i in 1:101){
x <- xvals[i]
approx <- coefs[5] + coefs[4] * x + coefs[3] * x^2 + coefs[2] *x^3 + coefs[1] *x^4
func <- exp(x)
error <- abs(func - approx)
Approx[i] <- approx
Func[i] <- func
Error[i] <- error
}
plotData <- data.frame(X = xvals, fx = Func, approx = Approx, error = Error )
#Plot approximate error
p <- ggplot() + geom_line(data = plotData, aes(x = X, y = approx), color = "black") + geom_line(data = plotData, aes(x = X, y = fx), color = "red")  + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
print(p)
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = error) + geom_line() + xlab('X') + ylab('Error') + ggtitle('Error in Taylor Expansion of e^x')
for (i in 1:101){
x <- xvals[i]
approx <- coefs[5] + coefs[4] * x + coefs[3] * x^2 + coefs[2] *x^3 + coefs[1] *x^4
func <- exp(x)
error <- func - approx
Approx[i] <- approx
Func[i] <- func
Error[i] <- error
}
plotData <- data.frame(X = xvals, fx = Func, approx = Approx, error = Error )
#Plot approximate error
p <- ggplot() + geom_line(data = plotData, aes(x = X, y = approx), color = "black") + geom_line(data = plotData, aes(x = X, y = fx), color = "red")  + xlab('X') + ylab('Approximation') + ggtitle('Taylor Expansion of e^x near 0')
print(p)
#Plot approximate error
plotData %>% ggplot() + aes(x = X, y = error) + geom_line() + xlab('X') + ylab('Error') + ggtitle('Error in Taylor Expansion of e^x')
setwd("C:\\Users\\jorda\\Workspace\\mban\\Code\\ML_Team_Project")
library(dplyr)
library(tidyr)
library(ROCR)
library(class)
library(caret)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest) #for bagging and random forests
library(gbm) #for boosting
crimesFull = read.csv("cleanedCrimesData.csv")
crimesFull <- crimesFull %>% select(-mixedCommunity, -immigrantCommunity)
View(crimesFull)
crimesFull <- crimesFull %>% select(-mixedCommunity, -immigrantCommunity, -X)
crimesFull = read.csv("cleanedCrimesData.csv")
crimesFull <- crimesFull %>% select(-mixedCommunity, -immigrantCommunity, -X)
set.seed(657)
split = createDataPartition(crimesFull$violentcrimesperpopulation, p = 0.65, list = FALSE)
train = crimesFull[split,]
test = crimesFull[-split,]
#Medium ntrees, medium shrinkage, medium interaction depth
n.trees2 = 30000
shrinkage2 = 0.0005
interaction.depth2 = 6
minobs = 25
# Again, we can manually control the parameters
boost.mod2 = gbm(violentcrimesperpopulation~.,data=train,distribution = "gaussian",n.minobsinnode = minobs, n.trees=n.trees2, shrinkage=shrinkage2, interaction.depth=interaction.depth2)
# Save the influence for the report
influence2 = varImp(boost.mod2, n.trees2)
predTrain <- predict(boost.mod2, train, n.trees= n.trees2)
predTest <- predict(boost.mod2, test, n.trees= n.trees2)
View(influence2)
View(influence2)
trainSSE <- sum((predTrain- train$violentcrimesperpopulation)^2)
trainSST <- sum((mean(train$violentcrimesperpopulation)- train$violentcrimesperpopulation)^2)
trainOSR2 <- 1-trainSSE/trainSST
testSSE <- sum((predTest- test$violentcrimesperpopulation)^2)
testSST <- sum((mean(train$violentcrimesperpopulation)- test$violentcrimesperpopulation)^2)
testOSR2 <- 1-testSSE/testSST
#Use the recitation code to train the out-of-bag predictions, setting ntree and nodesize specifically
train.rf.oob <- train(x = train %>% select(-violentcrimesperpopulation),
y = train$violentcrimesperpopulation,
method="rf",
ntree= 150,
nodesize=25,
tuneGrid=data.frame(mtry=1:40),          # use default nodesize & ntree
trControl=trainControl(method="oob"))
train.rf.oob <- train(x = train %>% select(-violentcrimesperpopulation),
y = train$violentcrimesperpopulation,
method="rf",
ntree= 150,
nodesize=25,
tuneGrid=data.frame(mtry=1:15),          # use default nodesize & ntree
trControl=trainControl(method="oob"))
View(train)
rf.cv = randomForest(violentcrimesperpopulation~., data=train, ntree=200,mtry=25,nodesize=25)
View(train)
source('C:/Users/jorda/Workspace/mban/Code/ML_Team_Project/Preprocessing/IdentifyKeyVariables.R', echo=TRUE)
crimesFull = read.csv("cleanedCrimesData.csv")
crimesFull <- crimesFull %>% select(-mixedCommunity, -immigrantCommunity, -X, -otherpercap)
set.seed(657)
split = createDataPartition(crimesFull$violentcrimesperpopulation, p = 0.65, list = FALSE)
train = crimesFull[split,]
test = crimesFull[-split,]
#Medium ntrees, medium shrinkage, medium interaction depth
n.trees2 = 30000
shrinkage2 = 0.0005
interaction.depth2 = 6
minobs = 25
rf.cv = randomForest(violentcrimesperpopulation~., data=train, ntree=200,mtry=25,nodesize=25)
#Use the recitation code to train the out-of-bag predictions, setting ntree and nodesize specifically
train.rf.oob <- train(x = train %>% select(-violentcrimesperpopulation),
y = train$violentcrimesperpopulation,
method="rf",
ntree=80,
nodesize=25,
tuneGrid=data.frame(mtry=1:40),          # use default nodesize & ntree
trControl=trainControl(method="oob"))
# Plot Results as a Line Graph
ggplot(train.rf.oob$results, aes(x=mtry, y=Rsquared)) +
geom_point(size=5) +
theme_bw() +
xlab("Number of variables per split") +
ylab("Out-of-bag R2") +
ggtitle("Cross-Validation: OOB R2 vs Number of Vars Per Split")+
scale_x_continuous(breaks=1:80, name="mtry") +
theme(axis.title=element_text(size=18), axis.text=element_text(size=12))
rf.cv = randomForest(violentcrimesperpopulation~., data=train, ntree=80,mtry=best.mtry,nodesize=25)
best.mtry <- train.rf.oob$bestTune[[1]]
rf.cv = randomForest(violentcrimesperpopulation~., data=train, ntree=80,mtry=best.mtry,nodesize=25)
predTrain <- predict(boost.mod2, train, n.trees= n.trees2)
predTest <- predict(boost.mod2, test, n.trees= n.trees2)
predTrainRF <- predict(rf.cv, train, n.trees= n.trees2)
predTestRF <- predict(rf.cv, test, n.trees= n.trees2)
trainSSERF <- sum((predTrain- train$violentcrimesperpopulation)^2)
trainSSTRF <- sum((mean(train$violentcrimesperpopulation)- train$violentcrimesperpopulation)^2)
trainOSR2RF <- 1-trainSSE/trainSST
testSSERF <- sum((predTest- test$violentcrimesperpopulation)^2)
testSSTRF <- sum((mean(train$violentcrimesperpopulation)- test$violentcrimesperpopulation)^2)
testOSR2RF <- 1-testSSE/testSST
rf.cv = randomForest(violentcrimesperpopulation~., data=train, ntree=80,mtry=best.mtry,nodesize=25)
predTrainRF <- predict(rf.cv, train, n.trees= n.trees2)
predTestRF <- predict(rf.cv, test, n.trees= n.trees2)
trainSSERF <- sum((predTrainRF- train$violentcrimesperpopulation)^2)
trainSSTRF <- sum((mean(train$violentcrimesperpopulation)- train$violentcrimesperpopulation)^2)
trainOSR2RF <- 1-trainSSE/trainSST
testSSERF <- sum((predTestRF- test$violentcrimesperpopulation)^2)
testSSTRF <- sum((mean(train$violentcrimesperpopulation)- test$violentcrimesperpopulation)^2)
testOSR2RF <- 1-testSSE/testSST
trainSSERF <- sum((predTrainRF- train$violentcrimesperpopulation)^2)
trainSSERF <- sum((predTrainRF- train$violentcrimesperpopulation)^2)
trainSSTRF <- sum((mean(train$violentcrimesperpopulation)- train$violentcrimesperpopulation)^2)
trainOSR2RF <- 1-trainSSERF/trainSSTRF
testSSERF <- sum((predTestRF- test$violentcrimesperpopulation)^2)
testSSTRF <- sum((mean(train$violentcrimesperpopulation)- test$violentcrimesperpopulation)^2)
testOSR2RF <- 1-testSSERF/testSSTRF
#Medium ntrees, medium shrinkage, medium interaction depth
n.trees2 = 30000
shrinkage2 = 0.0005
interaction.depth2 = 6
minobs = 25
# Again, we can manually control the parameters
boost.mod2 = gbm(violentcrimesperpopulation~.,data=train,distribution = "gaussian",n.minobsinnode = minobs, n.trees=n.trees2, shrinkage=shrinkage2, interaction.depth=interaction.depth2)
# Save the influence for the report
influence2 = varImp(boost.mod2, n.trees2)
predTrain <- predict(boost.mod2, train, n.trees= n.trees2)
predTest <- predict(boost.mod2, test, n.trees= n.trees2)
trainSSE <- sum((predTrain- train$violentcrimesperpopulation)^2)
trainSST <- sum((mean(train$violentcrimesperpopulation)- train$violentcrimesperpopulation)^2)
trainOSR2 <- 1-trainSSE/trainSST
testSSE <- sum((predTest- test$violentcrimesperpopulation)^2)
testSST <- sum((mean(train$violentcrimesperpopulation)- test$violentcrimesperpopulation)^2)
testOSR2 <- 1-testSSE/testSST
# Save the influence for the report
influence2 = varImp(boost.mod2, n.trees2)
View(influence2)
View(influence2)
influenceRF = varImp(rf.cv)
influenceRF = summary(rf.cv)
importance.rf <- data.frame(imp=importance(rf.cv))
View(importance.rf)
View(importance.rf)
View(boost.mod2)
View(boost.mod2)
View(rf.cv)
View(rf.cv)
View(influence2)
View(influence2)
setwd("C:\\Users\\jorda\\Workspace\\mban\\Code\\ML_Team_Project")
crimesFull <- crimesFull %>% select(pctilleg, pctkids2par, numilleg, racepctwhite, racepctblack, pctpersdensehouse, pctfam2par, pctvacantboarded, numstreet, pcthouseless3br, malepctdivorce, mixedCommunity, immigrantCommunity)
crimesFull <- read.csv("cleanedCrimesData.csv")
crimesFull <- crimesFull %>% select(pctilleg, pctkids2par, numilleg, racepctwhite, racepctblack, pctpersdensehouse, pctfam2par, pctvacantboarded, numstreet, pcthouseless3br, malepctdivorce, mixedCommunity, immigrantCommunity)
write.csv(crimesFull, "fairRegressionData.csv")
setwd("C:\\Users\\jorda\\Workspace\\mban\\Code\\ML_Team_Project")
crimesFull <- read.csv("cleanedCrimesData.csv")
crimesFull <- crimesFull %>% select(pctilleg, pctkids2par, numilleg, racepctwhite, racepctblack, pctpersdensehouse, pctfam2par, pctvacantboarded, numstreet, pcthouseless3br, malepctdivorce, mixedCommunity, immigrantCommunity, violentcrimesperpopulation)
write.csv(crimesFull, "fairRegressionData.csv")
write.csv(crimesFull, "fairRegressionData.csv")
setwd("C:\\Users\\jorda\\Workspace\\mban\\Code\\ML_Team_Project")
library(dplyr)
library(tidyr)
crimes <- read.csv("Data/communities.data")
crimes <- crimes %>% select(-state, -county, -community, -fold, -communityname, -lemasswornft, -lemasswftperpop, -lemasgangunitdeployed, -lemasswftfieldops, -lemasswftfieldperpop, -lemastotalreq, -lemastotreqperpop, -lemaspctofficedrugunits, -lemaspctpoliceonpatrol, -policecars, -policeperpop, -policeoperbudget, -policebudgetperpop, -policeaveotworked, -numkindsdrugsseized, -officersassgndrugunits, -pctpoliceminority, -pctpoliceasian, -pctpolicewhite, -pctpoliceblack, -racialmatchcommpolice, -policereqperofficer, -pctpolicehisp)
meanasian = mean(crimes$racepctasian)
meanblack = mean(crimes$racepctblack)
meanhisp = mean(crimes$racepcthisp)
meanimmig = mean(crimes$pctpoprecentimmig)
crimes <- crimes %>% mutate(mixedCommunity = ifelse((racepcthisp > meanhisp) | (racepctblack > meanblack), 2, 1), immigrantCommunity = ifelse(pctpoprecentimmig > meanimmig, 2, 1))
write.csv(crimes, "cleanedCrimesData.csv")
View(crimes)
setwd("C:\\Users\\jorda\\Workspace\\mban\\Code\\ML_Team_Project")
crimesFull <- read.csv("cleanedCrimesData.csv")
crimesFull <- crimesFull %>% select(pctilleg, pctkids2par, numilleg, racepctwhite, racepctblack, pctpersdensehouse, pctfam2par, pctvacantboarded, numstreet, pcthouseless3br, malepctdivorce, mixedCommunity, immigrantCommunity, violentcrimesperpopulation)
write.csv(crimesFull, "fairRegressionData.csv")
q()
